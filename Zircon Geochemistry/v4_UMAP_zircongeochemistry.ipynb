{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UMAP script to reduce zircon geochemistry\n",
    "#2024-10-03 MAAZ\n",
    "#2025-06-26, EBL\n",
    "\n",
    "# input CG2024 dataset and select parameters (if not already input)\n",
    "# run UMAP\n",
    "# test UMAP diagnostic plotting, local dimension, PCA RGB values for global structure\n",
    "# create decision boundary - linear SVC\n",
    "# ROC_AUC curve calculation\n",
    "# Plot global geochemistry in UMAP\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import umap\n",
    "import umap.plot\n",
    "# import scipy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import colorcet as cc\n",
    "import plotly.express as px #for plottly\n",
    "import joblib #for saving UMAP model\n",
    "\n",
    "from matplotlib import colors\n",
    "\n",
    "#Machine learning libraries\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_circles, make_classification, make_moons\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, ShuffleSplit, KFold\n",
    "from sklearn.metrics import roc_curve, auc, balanced_accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "\n",
    "#Advanced plotting libraries\n",
    "from itertools import compress\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from bokeh.plotting import output_notebook #for interactive plot\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "#Script requirements\n",
    "umap.plot.output_notebook() #resources= INLINE\n",
    "%matplotlib inline\n",
    "#%matplotlib widget #for 3d plot\n",
    "sns.set_theme(style='white', context='notebook', rc={'figure.figsize':(14, 10)}) #anything smaller does not help with points\n",
    "\n",
    "#Helper functions\n",
    "def export_legend(legend, filepath2, expand=[-5,-5,5,5]):   \n",
    "\n",
    "    fig  = legend.figure\n",
    "    fig.canvas.draw()\n",
    "    bbox  = legend.get_window_extent()\n",
    "    bbox = bbox.from_extents(*(bbox.extents + np.array(expand)))\n",
    "    bbox = bbox.transformed(fig.dpi_scale_trans.inverted())\n",
    "    \n",
    "    fig.savefig(filepath2, dpi=\"figure\", bbox_inches=bbox)\n",
    "\n",
    "def make_dir(destDir):\n",
    "    image_dir = destDir\n",
    "    if not os.path.exists(image_dir):\n",
    "        os.makedirs(image_dir)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#User input - change directories \n",
    "data_folder1 = # add here\n",
    "\n",
    "file1 = \"CG2024data_v4.csv\"\n",
    "file2 = \"legend.png\" #plot\n",
    "file3 = \"workable_table.xlsx\" #for reproducibility\n",
    "file4 = \"standard_scaler.xml\"\n",
    "file5 = \"umap_model.xml\" \n",
    "\n",
    "trial_name = 'V4_zircongeochemistry' #IMPORTANT: change this name to avoid overwriting outputs\n",
    "\n",
    "\n",
    "#Script begins\n",
    "\n",
    "os.chdir(data_folder1)\n",
    "print(data_folder1)\n",
    "\n",
    "data_folder2 = os.path.join(os.path.dirname(data_folder1), 'outputs', trial_name)\n",
    "make_dir(data_folder2)\n",
    "\n",
    "\n",
    "filepath1 = os.path.join(data_folder1, file1)\n",
    "filepath2 = os.path.join(data_folder2, file2)\n",
    "filepath3 = os.path.join(data_folder2, file3)\n",
    "filepath4 = os.path.join(data_folder2, file4)\n",
    "filepath5 = os.path.join(data_folder2, file5)\n",
    "\n",
    "#Load table (the column indexes below can be obtained from a data dictionary)\n",
    "table1 = pd.read_csv(filepath1, low_memory=False)\n",
    "table1.head()\n",
    "\n",
    "range_imputed = list([0, 1, 2, 5, 6, 9, 10,11, 16, 18, 37,39,22,26,30,35,46,47,49,63])\n",
    "range_imputed.extend(list([19,23,27,36,38,78,80,67,68,69,72,74,75,76,77]))\n",
    "\n",
    "\n",
    "#Generating workable table\n",
    "table2 = table1.iloc[:, range_imputed] \n",
    "\n",
    "#medicine 1\n",
    "idx1 = table2.Temporality.isnull()\n",
    "idx2 = table2[\"DepositBatholith\"].isnull()\n",
    "idx3 = table2[\"Sample\"].isnull()\n",
    "idx4 = table2[\"Continent\"].isnull()\n",
    "idx5 = table2[\"Composition\"].isnull()\n",
    "idx6 = table2[\"ID\"].isnull()\n",
    "idx7 = table2[\"District\"].isnull()\n",
    "idx8 = table2[\"U\"].isnull()\n",
    "idx9 = table2[\"Ti\"].isnull()\n",
    "idx10 = table2[\"La\"].isnull()\n",
    "idx11 = table2[\"Sm\"].isnull()\n",
    "idx12 = table2[\"Dy\"].isnull()\n",
    "idx13 = table2[\"Lu\"].isnull()\n",
    "idx14 = table2[\"Zr\"].isnull()\n",
    "idx15 = table2[\"Nb\"].isnull()\n",
    "idx16 = table2[\"Al\"].isnull()\n",
    "idx17 = table2[\"Zr_Age_Ma\"].isnull()\n",
    "\n",
    "\n",
    "table2.loc[idx1, \"Temporality\"] = 'Unknown'\n",
    "table2.loc[idx2, \"DepositBatholith\"] = 'Unknown'\n",
    "table2.loc[idx3, \"Sample\"] = 'Unknown'\n",
    "table2.loc[idx4, \"Continent\"] = 'Unknown'\n",
    "table2.loc[idx5, \"Composition\"] = 'Unknown'\n",
    "table2.loc[idx6, \"ID\"] = 'Unknown'\n",
    "table2.loc[idx7, \"District\"] = 'Unknown'\n",
    "table2.loc[idx8, \"U\"] = 0\n",
    "table2.loc[idx9, \"Ti\"] = 0\n",
    "table2.loc[idx10, \"La\"] = 0\n",
    "table2.loc[idx11, \"Sm\"] = 0\n",
    "table2.loc[idx12, \"Dy\"] = 0\n",
    "table2.loc[idx13, \"Lu\"] = 0\n",
    "table2.loc[idx14, \"Zr\"] = 0\n",
    "table2.loc[idx15, \"Nb\"] = 0\n",
    "table2.loc[idx16, \"Al\"] = 0\n",
    "table2.loc[idx17, \"Zr_Age_Ma\"] = 0\n",
    "\n",
    "#medicine 2: do not drop string NAs\n",
    "any_idx = table2.isna().any(axis=1)\n",
    "table3 = table2.loc[np.invert(any_idx), :] # np.invert(any_idx)\n",
    "table3.reset_index(inplace = True) #the index from the input table is preserved (for searching points)\n",
    "\n",
    "data_start_idx = 21 #10\n",
    "col_names = list(table3.columns)\n",
    "a = table2.shape[0]\n",
    "b = table3.shape[0]\n",
    "c = col_names[data_start_idx:]\n",
    "\n",
    "print(f\"Table 2 has {a} rows and Table 3 without NA has {b} rows\")\n",
    "print(f\"UMAP will use: {c}\")\n",
    "table3.head()\n",
    "table3.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and filtering data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing populations for each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricals = [\"ml_classes\", \"setID\", \"Dataset\", \"District\", \"DepositBatholith\", \"Temporality\", \"ID\", \"Sample\", \"Composition\", \"Continent\", \"Zr_Age_Ma\"]\n",
    "for i in range(len(categoricals)):\n",
    "    temp = table3.loc[:, [categoricals[i]]].value_counts()\n",
    "    print(temp)\n",
    "\n",
    "#table3.loc[:, [categoricals[1]]].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding space\n",
    "### Run only once each time the notebook is opened. The stochastic process within UMAP wont repeat itself for all plots otherwise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating and saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run UMAP IF not using UMAP model and saved scaler from file, if these have been created already, run the cell below instead\n",
    "\n",
    "try:\n",
    "    del embedding\n",
    "except:\n",
    "    print('Processing for the first time')\n",
    "\n",
    "components_output = 2 #default=2, dimensionality\n",
    "neighbors_input = 20 #default=15, preservation of local (> singletons) vs global structure\n",
    "min_dist_input = 0.003 #0.003, min. dist. of packing value (in low dimensional representation)\n",
    "\n",
    "#data\n",
    "data = table3.iloc[:, data_start_idx:].values\n",
    "sc = StandardScaler()\n",
    "scaled_data = sc.fit_transform(data) \n",
    "#print(\"Scaler mean: \", sc.mean_)\n",
    "#print(\"Scaler scale: \", sc.scale_)\n",
    "\n",
    "#umap object () for umap.plot\n",
    "embedding = umap.UMAP(n_neighbors= neighbors_input,\n",
    "                      min_dist= min_dist_input,\n",
    "                      metric='correlation', \n",
    "                      n_components= components_output,\n",
    "                     ).fit(scaled_data)  \n",
    "\n",
    "#Saving data for reproducibility\n",
    "table3.to_excel(filepath3, index=False) #processed table\n",
    "joblib.dump(sc, filepath4) #scaler\n",
    "joblib.dump(embedding, filepath5) #umap transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this IF using the saved scaler and UMAP transform from file, OR after running cell above\n",
    "\n",
    "sc = joblib.load(filepath4) #scaler\n",
    "embedding = joblib.load(filepath5) #umap transformation\n",
    "\n",
    "embedding2 = embedding.embedding_\n",
    "\n",
    "#Load table \n",
    "table3 = pd.read_excel(filepath3)\n",
    "table3.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UMAP diagnostic plotting, options can be pca, local_dim, vq\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax=umap.plot.diagnostic(embedding, diagnostic_type='local_dim',point_size=10, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA plotting to test if global structure is retained\n",
    "\n",
    "### first cell calculates CLR transformed PCA along with estimated ZrSiO content, second displays unscaled RGB values used to make UMAP coloured by PCA RGB points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#script for PCA\n",
    "\n",
    "emb = pd.DataFrame(embedding2)\n",
    "# Apply centered log transformation to the dataset using a calculated residual ZrSiO value\n",
    "\n",
    "#theoretical calc ZrO (1000000ppm- sum TE)\n",
    "Sum_TE = ['P', 'Ce', 'Eu', 'Th', 'Hf', 'Calculated_La', 'Calculated_Pr', 'Imputed_Y',\n",
    "          'Imputed_Nd', 'Imputed_Gd', 'Imputed_Er', 'Imputed_Yb', 'Imputed_Sm', 'Imputed_Dy', 'Imputed_Lu']\n",
    "\n",
    "\n",
    "Dat_UMAP = pd.concat([table3, emb.iloc[:, [0, 1]]], axis=1)\n",
    "Dat_UMAP['ZrSiO'] = 1_000_000 - table3[Sum_TE].sum(axis=1)\n",
    "\n",
    "\n",
    "# CLR transformation\n",
    "def centered_log_ratio_transform(X):\n",
    "    \"\"\"Centered log-ratio transformation for compositional data.\"\"\"\n",
    "    if np.any(X <= 0):\n",
    "        raise ValueError(\"CLR transformation requires strictly positive values.\")\n",
    "    geometric_mean = np.exp(np.mean(np.log(X), axis=1)).to_numpy().reshape(-1, 1)\n",
    "    return np.log(X / geometric_mean)\n",
    "\n",
    "# Correlation circle plot\n",
    "def plot_correlation_circle(loadings, title=\"Correlation Circle\"):\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    plt.axhline(0, color='gray', linestyle='--', linewidth=0.5)\n",
    "    plt.axvline(0, color='gray', linestyle='--', linewidth=0.5)\n",
    "    circle = plt.Circle((0, 0), 1, color='gray', fill=False, linestyle='--')\n",
    "    plt.gca().add_artist(circle)\n",
    "\n",
    "    x_axis, y_axis = loadings.columns[0], loadings.columns[1]\n",
    "    for i in range(loadings.shape[0]):\n",
    "        plt.arrow(0, 0, loadings.iloc[i, 0], loadings.iloc[i, 1],\n",
    "                  color='r', alpha=0.7, head_width=0.02)\n",
    "        plt.text(loadings.iloc[i, 0]*1.1, loadings.iloc[i, 1]*1.1,\n",
    "                 loadings.index[i], ha='center', va='center', fontsize=9)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel(x_axis)\n",
    "    plt.ylabel(y_axis)\n",
    "    plt.xlim(-1.1, 1.1)\n",
    "    plt.ylim(-1.1, 1.1)\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# PCA pipeline\n",
    "def run_pca_pipeline(df, clr_columns, group_column='ml_classes', n_components=3):\n",
    "    \n",
    "    features = df[clr_columns]\n",
    "    groups = df[group_column]\n",
    "\n",
    "    clr_scaled = pd.DataFrame(centered_log_ratio_transform(features),\n",
    "                            columns=features.columns, index=features.index)\n",
    "\n",
    "    pca = PCA(n_components=n_components)\n",
    "    principal_components = pca.fit_transform(clr_scaled)\n",
    "\n",
    "    pca_scores = pd.DataFrame(principal_components,\n",
    "                              columns=[f'PC{i+1}' for i in range(n_components)],\n",
    "                              index=df.index)\n",
    "    pca_scores[group_column] = groups\n",
    "\n",
    "    # Scree plot\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(range(1, n_components + 1),\n",
    "             pca.explained_variance_ratio_, marker='o', linestyle='--')\n",
    "    plt.title(\"Scree Plot\")\n",
    "    plt.xlabel(\"Principal Component\")\n",
    "    plt.ylabel(\"Explained Variance Ratio\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 2D Scatter Plot: PC1 vs PC2\n",
    "    plt.figure(figsize=(7, 6))\n",
    "    sns.scatterplot(data=pca_scores, x='PC1', y='PC2', hue=group_column, palette='Set2')\n",
    "    plt.title('PC1 vs PC2 Scatter Plot')\n",
    "    plt.xlabel(f\"PC1 ({pca.explained_variance_ratio_[0]*100:.1f}%)\")\n",
    "    plt.ylabel(f\"PC2 ({pca.explained_variance_ratio_[1]*100:.1f}%)\")\n",
    "    plt.axhline(0, color='gray', linestyle='--', linewidth=0.5)\n",
    "    plt.axvline(0, color='gray', linestyle='--', linewidth=0.5)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 3D Scatter Plot\n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    for group in pca_scores[group_column].unique():\n",
    "        group_data = pca_scores[pca_scores[group_column] == group]\n",
    "        ax.scatter(group_data['PC1'], group_data['PC2'], group_data['PC3'], label=group)\n",
    "    ax.set_xlabel(f\"PC1 ({pca.explained_variance_ratio_[0]*100:.1f}%)\")\n",
    "    ax.set_ylabel(f\"PC2 ({pca.explained_variance_ratio_[1]*100:.1f}%)\")\n",
    "    ax.set_zlabel(f\"PC3 ({pca.explained_variance_ratio_[2]*100:.1f}%)\")\n",
    "    ax.set_title(\"PC1 vs PC2 vs PC3 (3D Scatter Plot)\")\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Loadings\n",
    "    loadings = pd.DataFrame(pca.components_.T[:, :3],\n",
    "                            columns=['PC1', 'PC2', 'PC3'],\n",
    "                            index=features.columns)\n",
    "\n",
    "    plot_correlation_circle(loadings[['PC1', 'PC2']], title=\"Correlation Circle: PC1 vs PC2\")\n",
    "    plot_correlation_circle(loadings[['PC1', 'PC3']], title=\"Correlation Circle: PC1 vs PC3\")\n",
    "\n",
    "    print(\"PCA Loadings:\")\n",
    "    print(loadings.round(3))\n",
    "\n",
    "    return pca, pca_scores, loadings\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    group_labels = table3['ml_classes']\n",
    "    clr_columns = ['P', 'Ce', 'Eu', 'Th', 'Hf', 'Calculated_La', 'Calculated_Pr', 'Imputed_Y', \n",
    "                   'Imputed_Nd', 'Imputed_Gd', 'Imputed_Er', 'Imputed_Yb', 'Imputed_Sm', 'Imputed_Dy', 'Imputed_Lu', 'ZrSiO']\n",
    "    Dat_UMAP['ml_classes'] = pd.Series(group_labels, index=Dat_UMAP.index[:len(group_labels)])  # ensure group_labels matches df index\n",
    "    pca_model, pca_scores, pca_loadings = run_pca_pipeline(Dat_UMAP, clr_columns=clr_columns, group_column='ml_classes')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA to RGB to UMAP x, y\n",
    "\n",
    "\n",
    "def pca_to_rgb(pca_scores):\n",
    "    pcs = pca_scores[['PC1', 'PC2', 'PC3']].copy()\n",
    "    pcs_norm = np.zeros_like(pcs.values)\n",
    "\n",
    "    # PC 1-3 normalized to be from 0-1\n",
    "    for i in range(pcs.shape[1]):\n",
    "        norm = Normalize(vmin=pcs.iloc[:, i].min(), vmax=pcs.iloc[:, i].max())\n",
    "        pcs_norm[:, i] = norm(pcs.iloc[:, i])\n",
    "\n",
    "    # Convert to list of RGB tuples\n",
    "    rgb_colors = [tuple(color) for color in pcs_norm]\n",
    "    return np.array(rgb_colors)\n",
    "\n",
    "#give colour for mapping\n",
    "rgb_colors = pca_to_rgb(pca_scores)\n",
    "\n",
    "#PCA biplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# PC1 vs PC2\n",
    "axes[0].scatter(pca_scores['PC1'], pca_scores['PC2'],c=rgb_colors, s=20, alpha=0.9, edgecolor='k', linewidth=0.3)\n",
    "axes[0].set_xlabel('PC1')\n",
    "axes[0].set_ylabel('PC2')\n",
    "axes[0].set_title('PC1 vs PC2')\n",
    "\n",
    "# PC1 vs PC3\n",
    "axes[1].scatter(pca_scores['PC1'], pca_scores['PC3'],c=rgb_colors, s=20, alpha=0.9, edgecolor='k', linewidth=0.3)\n",
    "axes[1].set_xlabel('PC1')\n",
    "axes[1].set_ylabel('PC3')\n",
    "axes[1].set_title('PC1 vs PC3')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# UMAP plot using PCA colouring\n",
    "\n",
    "col_x = Dat_UMAP.columns[-3]\n",
    "col_y = Dat_UMAP.columns[-2]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(Dat_UMAP[col_x], Dat_UMAP[col_y],c=rgb_colors, s=20, alpha=0.9, edgecolor='k', linewidth=0.3)\n",
    "plt.xlabel(col_x)\n",
    "plt.ylabel(col_y)\n",
    "plt.title('UMAP Projection Colored by PCA RGB')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter variable below\n",
    "\n",
    "variable_legend = \"ml_classes\" #e.g., Temporality, ml_classes\n",
    "\n",
    "list_unique = table3[variable_legend].unique()\n",
    "n_classes = len(list_unique)\n",
    "\n",
    "#colourmap\n",
    "mapping = {item:i for i, item in enumerate(list_unique)}\n",
    "classif= table3[variable_legend].apply(lambda x: mapping[x]) #categorical array (same size as table3)\n",
    "colourmap = sns.color_palette(palette= cc.glasbey_category10, n_colors = n_classes)\n",
    "colours = [sns.color_palette(palette= colourmap)[x] for x in classif] #RGB triplets\n",
    "\n",
    "colourmap_updated = colourmap #pre-allocating\n",
    "for x in range(0, n_classes):\n",
    "    \n",
    "    idx = (classif == x)\n",
    "    name = list_unique[x]\n",
    "\n",
    "    colours_sub = colourmap[x]\n",
    "    \n",
    "    if name == 'Ore syn-mineral magmatism':\n",
    "        colours_sub = colors.to_rgb('red')\n",
    "\n",
    "    if name == 'Syn Mineral':\n",
    "        colours_sub = colors.to_rgb('red')\n",
    "\n",
    "    if name == 'Ore related magmatism':\n",
    "        target_colour = (255, 208, 0)\n",
    "        colours_sub = tuple(ti/255 for ti in target_colour)\n",
    "\n",
    "    if name == 'Unknown':\n",
    "        colours_sub = colors.to_rgb('lightgrey')\n",
    "\n",
    "    if name == 'S Type Granite':\n",
    "        colours_sub = colors.to_rgb('violet')\n",
    "\n",
    "    colourmap_updated[x] = colours_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter variable to be used as known labels for binary classification\n",
    "\n",
    "variable_legend = \"ml_classes\" #Temporality\n",
    "\n",
    "#medicine 3\n",
    "if variable_legend == \"Deposit/Batholith\":\n",
    "    variable_legend1 = \"Deposit-Batholith\"\n",
    "else:\n",
    "    variable_legend1 = variable_legend\n",
    "    \n",
    "\n",
    "list_unique = table3[variable_legend].unique()\n",
    "n_classes = len(list_unique)\n",
    "\n",
    "#colourmap\n",
    "mapping = {item:i for i, item in enumerate(list_unique)}\n",
    "classif= table3[variable_legend].apply(lambda x: mapping[x]) #categorical array (same size as table3)\n",
    "\n",
    "#panda series\n",
    "df = pd.DataFrame( dict(x=embedding2[:,0], y=embedding2[:,1], z= classif) ) \n",
    "X = df.iloc[:, 0:2].to_numpy()\n",
    "Y = df.iloc[:, 2].to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.4, random_state=42)\n",
    "x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
    "y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary decision plane using linear SVC, performance scores of binary model\n",
    "\n",
    "clf = SVC(kernel=\"linear\", C=0.025, random_state=42, probability= True) #C = 1 (regularisation)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "# score = clf.score(X_test, y_test) #mean accuracy \n",
    "\n",
    " # Predict using the best model\n",
    "best_model = clf #if cross-validation: .best_estimator_\n",
    "pred = best_model.predict(X_test)\n",
    "ac = balanced_accuracy_score(y_test, pred) # same as 'score'\n",
    "f1_ = f1_score(y_test, pred) # F1 scores\n",
    "\n",
    "# Receiver operating characteristic (ROC) area under the curve (AUC)\n",
    "probs = best_model.predict_proba(X_test)\n",
    "probs = probs[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, probs)\n",
    "auc_ = auc(fpr, tpr)\n",
    "\n",
    "print(\"=== Nested K-Fold Cross-Validation Scores ===\")\n",
    "print(\"Mean balanced accuracy: \"+ str(round(np.mean(ac), 3)))\n",
    "print(\"Mean F1: \"+ str(round(np.mean(f1_), 3)))\n",
    "print(\"Mean roc_auc: \"+ str(round(np.mean(auc_), 3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting ROC_AUC\n",
    "\n",
    "probs = best_model.predict_proba(X_test)\n",
    "probs = probs[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, probs)\n",
    "auc_ = auc(fpr, tpr)\n",
    "\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % auc_)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot global projection of zircon geochemistry from CG2024\n",
    "\n",
    "#Saving names\n",
    "filepath3_new = filepath2.replace(\"legend.png\", variable_legend1 + \"_legend.png\")\n",
    "filepath4_new = filepath2.replace(\"legend.png\", variable_legend1 + \"_plot.png\")\n",
    "print(filepath4_new)\n",
    "\n",
    "#Plot\n",
    "markerSize = 6\n",
    "fontSize = 18\n",
    "\n",
    "fig = plt.figure(dpi= 400,figsize=(8,6)) #1200 , figsize=(10, 10)\n",
    "\n",
    "for x in range(0, n_classes):\n",
    "\n",
    "    \n",
    "    idx = (classif == x)\n",
    "    name = list_unique[x]\n",
    "   \n",
    "    # colours_sub = list(compress(colours, idx)) #required to index list\n",
    "    colours_sub = np.asarray(colourmap_updated[x]).reshape(1,-1)        \n",
    "\n",
    "    scatter = plt.scatter(embedding2[idx, 0], embedding2[idx, 1],\n",
    "                              c=colours_sub, label = name,\n",
    "                              s= 20, alpha= .7, edgecolors= 'none')\n",
    "\n",
    "plt.xlabel(\"UMAP0\")\n",
    "plt.ylabel(\"UMAP1\")\n",
    "\n",
    "ax = plt.gca()\n",
    "cm = plt.cm.RdBu\n",
    "\n",
    "plt.gca().set_aspect('equal', 'datalim')\n",
    "\n",
    "lgnd = plt.legend(ncol=1, fontsize= fontSize, loc='center right', bbox_to_anchor=(1.4, 0.5),\n",
    "                  markerscale= 10, scatterpoints=1)\n",
    "export_legend(lgnd, filepath2= filepath3_new)\n",
    "lgnd.remove()\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(filepath4_new, dpi=\"figure\")\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
