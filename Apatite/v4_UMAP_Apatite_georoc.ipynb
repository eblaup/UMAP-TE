{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UMAP script to reduce zircon geochemistry\n",
    "#2024-10-03 MAAZ\n",
    "#2025-06-26, EBL\n",
    "\n",
    "# input CG2024 dataset and select parameters (if not already input)\n",
    "# run UMAP\n",
    "# create decision boundary - linear SVC\n",
    "# ROC_AUC curve calculation\n",
    "# Plot global geochemistry in umap\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import umap\n",
    "import umap.plot\n",
    "# import scipy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import colorcet as cc\n",
    "import plotly.express as px #for plottly\n",
    "import joblib #for saving UMAP model\n",
    "\n",
    "from matplotlib import colors\n",
    "\n",
    "#Machine learning libraries\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_circles, make_classification, make_moons\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, balanced_accuracy_score, f1_score\n",
    "\n",
    "#Advanced plotting libraries\n",
    "from itertools import compress\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from bokeh.plotting import output_notebook #for interactive plot\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "#Script requirements\n",
    "umap.plot.output_notebook() #resources= INLINE\n",
    "%matplotlib inline\n",
    "#%matplotlib widget #for 3d plot\n",
    "sns.set_theme(style='white', context='notebook', rc={'figure.figsize':(14, 10)}) #anything smaller does not help with points\n",
    "\n",
    "#Helper functions\n",
    "def export_legend(legend, filepath2, expand=[-5,-5,5,5]):   \n",
    "\n",
    "    fig  = legend.figure\n",
    "    fig.canvas.draw()\n",
    "    bbox  = legend.get_window_extent()\n",
    "    bbox = bbox.from_extents(*(bbox.extents + np.array(expand)))\n",
    "    bbox = bbox.transformed(fig.dpi_scale_trans.inverted())\n",
    "    \n",
    "    fig.savefig(filepath2, dpi=\"figure\", bbox_inches=bbox)\n",
    "\n",
    "def make_dir(destDir):\n",
    "    image_dir = destDir\n",
    "    if not os.path.exists(image_dir):\n",
    "        os.makedirs(image_dir)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and filtering data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#User input - change directories \n",
    "data_folder1 = # input directory here\n",
    "\n",
    "file1 = \"GeoROC_apatite_v1.csv\"\n",
    "file2 = \"legend.png\" #plot\n",
    "file3 = \"workable_table.xlsx\" #for reproducibility\n",
    "file4 = \"standard_scaler.xml\"\n",
    "file5 = \"umap_model.xml\" \n",
    "\n",
    "trial_name = 'v4_Apatite_georoc_1' #IMPORTANT: change this name to avoid overwriting outputs\n",
    "\n",
    "\n",
    "#Script begins\n",
    "\n",
    "os.chdir(data_folder1)\n",
    "print(data_folder1)\n",
    "\n",
    "data_folder2 = os.path.join(os.path.dirname(data_folder1), 'outputs', trial_name)\n",
    "make_dir(data_folder2)\n",
    "\n",
    "\n",
    "filepath1 = os.path.join(data_folder1, file1)\n",
    "filepath2 = os.path.join(data_folder2, file2)\n",
    "filepath3 = os.path.join(data_folder2, file3)\n",
    "filepath4 = os.path.join(data_folder2, file4)\n",
    "filepath5 = os.path.join(data_folder2, file5)\n",
    "\n",
    "#Load table (the column indexes below can be obtained from a data dictionary)\n",
    "table1 = pd.read_csv(filepath1, low_memory=False)\n",
    "table1.head()\n",
    "\n",
    "#range_imputed = list([2,3,4,5,14,19,26,29,39,54,55,56,57,58,59,60,61,62,63,64,65,66,50,51])\n",
    "range_imputed = list([2,3,4,5,14,19,29,30,54,34,37,47])\n",
    "\n",
    "\n",
    "#range_imputed = list([0, 1, 2,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40])\n",
    "#range_imputed.extend(list([19,23,27,36,38,78,80,67,68,69,72,74,75,76,77]))\n",
    "#range_imputed.extend(range(65, 77)) #imputed REE\n",
    "\n",
    "\n",
    "#r1\n",
    "#range_imputed.extend(list([85,90,19,97,39]))\n",
    "\n",
    "#Generating workable table\n",
    "table2 = table1.iloc[:, range_imputed] \n",
    "\n",
    "#medicine 1\n",
    "idx1 = table2[\"TECTONIC SETTING\"].isnull()\n",
    "idx2 = table2[\"LOCATION\"].isnull()\n",
    "#idx3 = table2[\"LAND/SEA (SAMPLING)\"].isnull()\n",
    "idx4 = table2[\"ROCK NAME\"].isnull()\n",
    "#idx5 = table2[\"PRIMARY/SECONDARY\"].isnull()\n",
    "idx6 = table2[\"CITATION\"].isnull()\n",
    "\n",
    "\n",
    "table2.loc[idx1, \"TECTONIC SETTING\"] = 'Unknown'\n",
    "table2.loc[idx2, \"LOCATION\"] = 'Unknown'\n",
    "#table2.loc[idx3, \"LAND/SEA (SAMPLING)\"] = 'Unknown'\n",
    "table2.loc[idx4, \"ROCK NAME\"] = 'Unknown'\n",
    "#table2.loc[idx5, \"PRIMARY/SECONDARY\"] = 'Unknown'\n",
    "table2.loc[idx6, \"CITATION\"] = 'Unknown'\n",
    "\n",
    "#Dropping rows with empty cells\n",
    "\n",
    "#medicine 2: do not drop string NAs\n",
    "any_idx = table2.isna().any(axis=1)\n",
    "table3 = table2.loc[np.invert(any_idx), :] # np.invert(any_idx)\n",
    "table3.reset_index(inplace = True) #the index from the input table is preserved (for searching points)\n",
    "\n",
    "data_start_idx = 7 #10\n",
    "col_names = list(table3.columns)\n",
    "a = table2.shape[0]\n",
    "b = table3.shape[0]\n",
    "c = col_names[data_start_idx:]\n",
    "\n",
    "print(f\"Table 2 has {a} rows and Table 3 without NA has {b} rows\")\n",
    "print(f\"UMAP will use: {c}\")\n",
    "#table3.head()\n",
    "table3.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing populations for each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricals = [\"SAMPLE NAME\",\n",
    "                \"TECTONIC SETTING\",\n",
    "                \"LOCATION\",\n",
    "               \"ROCK NAME\"]\n",
    "for i in range(len(categoricals)):\n",
    "    temp = table3.loc[:, [categoricals[i]]].value_counts()\n",
    "    print(temp)\n",
    "\n",
    "#table3.loc[:, [categoricals[1]]].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding space\n",
    "### Run only once each time the notebook is opened. The stochastic process within UMAP wont repeat itself for all plots otherwise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating and saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run UMAP IF not using UMAP model and saved scaler from file, if these have been created already, run the cell below instead\n",
    "\n",
    "try:\n",
    "    del embedding\n",
    "except:\n",
    "    print('Processing for the first time')\n",
    "\n",
    "components_output = 2 #default=2, dimensionality\n",
    "neighbors_input = 20 #default=15, preservation of local (> singletons) vs global structure\n",
    "min_dist_input = 0.05 #0.003, min. dist. of packing value (in low dimensional representation)\n",
    "\n",
    "#data\n",
    "data = table3.iloc[:, data_start_idx:].values\n",
    "\n",
    "sc = StandardScaler()\n",
    "scaled_data = sc.fit_transform(data)\n",
    "\n",
    "#umap object () for umap.plot\n",
    "embedding = umap.UMAP(n_neighbors= neighbors_input,\n",
    "                      min_dist= min_dist_input,\n",
    "                      metric='correlation', \n",
    "                      n_components= components_output,\n",
    "                     ).fit(scaled_data)  \n",
    "\n",
    "#Saving data for reproducibility\n",
    "table3.to_excel(filepath3, index=False) #processed table\n",
    "joblib.dump(sc, filepath4) #scaler\n",
    "joblib.dump(embedding, filepath5) #umap transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading model and workable table from previous session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this IF using the saved scaler and UMAP transform from file, OR after running cell above\n",
    "\n",
    "sc = joblib.load(filepath4) #scaler\n",
    "embedding = joblib.load(filepath5) #umap transformation\n",
    "\n",
    "embedding2 = embedding.embedding_\n",
    "\n",
    "#Load table \n",
    "table3 = pd.read_excel(filepath3)\n",
    "table3.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UMAP diagnostic plotting\n",
    "fig, ax = plt.subplots(figsize=(16,8))\n",
    "ax=umap.plot.diagnostic(embedding, diagnostic_type='local_dim',point_size=20, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA after transformation to understand global structure preservation in UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply centered log transformation to the dataset and create a calculated theoretical CaPo content\n",
    "emb = pd.DataFrame(embedding2)\n",
    "\n",
    "\n",
    "#theoretical calc (1000000ppm- sum TE)\n",
    "\n",
    "#copy paste from list under cell 2\n",
    "Sum_TE = ['SR(PPM)', 'Y(PPM)', 'Eu/Eu*', 'LA(PPM)', 'ND(PPM)', 'LU(PPM)']\n",
    "Dat_UMAP = pd.concat([table3, emb.iloc[:, [0, 1]]], axis=1)\n",
    "Dat_UMAP['CaPO'] = 1_000_000 - table3[Sum_TE].sum(axis=1)\n",
    "\n",
    "#group variables and calc parameter for CLR transformation\n",
    "\n",
    "# CLR transformation\n",
    "def centered_log_ratio_transform(X):\n",
    "    \"\"\"Centered log-ratio transformation for compositional data.\"\"\"\n",
    "    if np.any(X <= 0):\n",
    "        raise ValueError(\"CLR transformation requires strictly positive values.\")\n",
    "    geometric_mean = np.exp(np.mean(np.log(X), axis=1)).to_numpy().reshape(-1, 1)\n",
    "    return np.log(X / geometric_mean)\n",
    "\n",
    "# Correlation circle plot\n",
    "def plot_correlation_circle(loadings, title=\"Correlation Circle\"):\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    plt.axhline(0, color='gray', linestyle='--', linewidth=0.5)\n",
    "    plt.axvline(0, color='gray', linestyle='--', linewidth=0.5)\n",
    "    circle = plt.Circle((0, 0), 1, color='gray', fill=False, linestyle='--')\n",
    "    plt.gca().add_artist(circle)\n",
    "\n",
    "    x_axis, y_axis = loadings.columns[0], loadings.columns[1]\n",
    "    for i in range(loadings.shape[0]):\n",
    "        plt.arrow(0, 0, loadings.iloc[i, 0], loadings.iloc[i, 1],\n",
    "                  color='r', alpha=0.7, head_width=0.02)\n",
    "        plt.text(loadings.iloc[i, 0]*1.1, loadings.iloc[i, 1]*1.1,\n",
    "                 loadings.index[i], ha='center', va='center', fontsize=9)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel(x_axis)\n",
    "    plt.ylabel(y_axis)\n",
    "    plt.xlim(-1.1, 1.1)\n",
    "    plt.ylim(-1.1, 1.1)\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# PCA pipeline\n",
    "def run_pca_pipeline(df, clr_columns, group_column='TECTONIC SETTING', n_components=3):\n",
    "    features = df[clr_columns]\n",
    "    groups = df[group_column]\n",
    "\n",
    "    clr_scaled = pd.DataFrame(centered_log_ratio_transform(features),\n",
    "                            columns=features.columns, index=features.index)\n",
    "\n",
    "    pca = PCA(n_components=n_components)\n",
    "    principal_components = pca.fit_transform(clr_scaled)\n",
    "\n",
    "    pca_scores = pd.DataFrame(principal_components,\n",
    "                              columns=[f'PC{i+1}' for i in range(n_components)],\n",
    "                              index=df.index)\n",
    "    pca_scores[group_column] = groups\n",
    "\n",
    "    # Scree plot\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(range(1, n_components + 1),\n",
    "             pca.explained_variance_ratio_, marker='o', linestyle='--')\n",
    "    plt.title(\"Scree Plot\")\n",
    "    plt.xlabel(\"Principal Component\")\n",
    "    plt.ylabel(\"Explained Variance Ratio\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 2D Scatter Plot: PC1 vs PC2\n",
    "    plt.figure(figsize=(7, 6))\n",
    "    sns.scatterplot(data=pca_scores, x='PC1', y='PC2', hue=group_column, palette='Set2')\n",
    "    plt.title('PC1 vs PC2 Scatter Plot')\n",
    "    plt.xlabel(f\"PC1 ({pca.explained_variance_ratio_[0]*100:.1f}%)\")\n",
    "    plt.ylabel(f\"PC2 ({pca.explained_variance_ratio_[1]*100:.1f}%)\")\n",
    "    plt.axhline(0, color='gray', linestyle='--', linewidth=0.5)\n",
    "    plt.axvline(0, color='gray', linestyle='--', linewidth=0.5)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 3D Scatter Plot\n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    for group in pca_scores[group_column].unique():\n",
    "        group_data = pca_scores[pca_scores[group_column] == group]\n",
    "        ax.scatter(group_data['PC1'], group_data['PC2'], group_data['PC3'], label=group)\n",
    "    ax.set_xlabel(f\"PC1 ({pca.explained_variance_ratio_[0]*100:.1f}%)\")\n",
    "    ax.set_ylabel(f\"PC2 ({pca.explained_variance_ratio_[1]*100:.1f}%)\")\n",
    "    ax.set_zlabel(f\"PC3 ({pca.explained_variance_ratio_[2]*100:.1f}%)\")\n",
    "    ax.set_title(\"PC1 vs PC2 vs PC3 (3D Scatter Plot)\")\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Loadings\n",
    "    loadings = pd.DataFrame(pca.components_.T[:, :3],\n",
    "                            columns=['PC1', 'PC2', 'PC3'],\n",
    "                            index=features.columns)\n",
    "\n",
    "    plot_correlation_circle(loadings[['PC1', 'PC2']], title=\"Correlation Circle: PC1 vs PC2\")\n",
    "    plot_correlation_circle(loadings[['PC1', 'PC3']], title=\"Correlation Circle: PC1 vs PC3\")\n",
    "\n",
    "    print(\"\\nðŸ“Œ PCA Loadings (First 3 PCs):\")\n",
    "    print(loadings.round(3))\n",
    "\n",
    "    return pca, pca_scores, loadings\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    group_labels = table3['TECTONIC SETTING']\n",
    "    clr_columns = ['SR(PPM)', 'Y(PPM)', 'Eu/Eu*', 'LA(PPM)', 'ND(PPM)', 'LU(PPM)',\"CaPO\"]\n",
    "    Dat_UMAP['TECTONIC SETTING'] = pd.Series(group_labels, index=Dat_UMAP.index[:len(group_labels)])  # ensure group_labels matches df index\n",
    "    pca_model, pca_scores, pca_loadings = run_pca_pipeline(Dat_UMAP, clr_columns=clr_columns, group_column='TECTONIC SETTING')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA to RGB to UMAP x, y\n",
    "\n",
    "\n",
    "def pca_to_rgb(pca_scores):\n",
    "    pcs = pca_scores[['PC1', 'PC2', 'PC3']].copy()\n",
    "    pcs_norm = np.zeros_like(pcs.values)\n",
    "\n",
    "    # PC 1-3 normalized to be from 0-1\n",
    "    for i in range(pcs.shape[1]):\n",
    "        norm = Normalize(vmin=pcs.iloc[:, i].min(), vmax=pcs.iloc[:, i].max())\n",
    "        pcs_norm[:, i] = norm(pcs.iloc[:, i])\n",
    "\n",
    "    # Convert to list of RGB tuples\n",
    "    rgb_colors = [tuple(color) for color in pcs_norm]\n",
    "    return np.array(rgb_colors)\n",
    "\n",
    "#give colour for mapping\n",
    "rgb_colors = pca_to_rgb(pca_scores)\n",
    "\n",
    "#PCA biplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# PC1 vs PC2\n",
    "axes[0].scatter(pca_scores['PC1'], pca_scores['PC2'],c=rgb_colors, s=30, alpha=0.9, edgecolor='k', linewidth=0.3)\n",
    "axes[0].set_xlabel('PC1')\n",
    "axes[0].set_ylabel('PC2')\n",
    "axes[0].set_title('PC1 vs PC2')\n",
    "\n",
    "# PC1 vs PC3\n",
    "axes[1].scatter(pca_scores['PC1'], pca_scores['PC3'],c=rgb_colors, s=30, alpha=0.9, edgecolor='k', linewidth=0.3)\n",
    "axes[1].set_xlabel('PC1')\n",
    "axes[1].set_ylabel('PC3')\n",
    "axes[1].set_title('PC1 vs PC3')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# UMAP plot using PCA colouring\n",
    "\n",
    "col_x = Dat_UMAP.columns[-3]\n",
    "col_y = Dat_UMAP.columns[-2]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(Dat_UMAP[col_x], Dat_UMAP[col_y],c=rgb_colors, s=30, alpha=0.9, edgecolor='k', linewidth=0.3)\n",
    "plt.xlabel(col_x)\n",
    "plt.ylabel(col_y)\n",
    "plt.title('UMAP Projection Colored by PCA RGB')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting UMAP plot coloured by variable, e.g. Lithology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter variable below\n",
    "\n",
    "variable_legend = \"LITHOLOGY CODE\" #e.g., Temporality, ml_classes\n",
    "\n",
    "list_unique = table3[variable_legend].unique()\n",
    "n_classes = len(list_unique)\n",
    "\n",
    "#colourmap\n",
    "mapping = {item:i for i, item in enumerate(list_unique)}\n",
    "classif= table3[variable_legend].apply(lambda x: mapping[x]) #categorical array (same size as table3)\n",
    "colourmap = sns.color_palette(palette= cc.glasbey_category10, n_colors = n_classes)\n",
    "colours = [sns.color_palette(palette= colourmap)[x] for x in classif] #RGB triplets\n",
    "\n",
    "colourmap_updated = colourmap #pre-allocating\n",
    "for x in range(0, n_classes):\n",
    "    \n",
    "    idx = (classif == x)\n",
    "    name = list_unique[x]\n",
    "\n",
    "    colours_sub = colourmap[x]\n",
    "    \n",
    "    if name == 'Ore syn-mineral magmatism':\n",
    "        colours_sub = colors.to_rgb('red')\n",
    "\n",
    "    if name == 'Syn Mineral':\n",
    "        colours_sub = colors.to_rgb('red')\n",
    "\n",
    "    if name == 'Ore related magmatism':\n",
    "        target_colour = (255, 208, 0)\n",
    "        colours_sub = tuple(ti/255 for ti in target_colour)\n",
    "\n",
    "    if name == 'Unknown':\n",
    "        colours_sub = colors.to_rgb('lightgrey')\n",
    "\n",
    "    if name == 'S Type Granite':\n",
    "        colours_sub = colors.to_rgb('violet')\n",
    "\n",
    "    colourmap_updated[x] = colours_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot global projection of zircon geochemistry from CG2024\n",
    "\n",
    "variable_legend1=\"LITHOLOGY CODE\"\n",
    "\n",
    "#Saving names\n",
    "filepath3_new = filepath2.replace(\"legend.png\", variable_legend1 + \"_legend.png\")\n",
    "filepath4_new = filepath2.replace(\"legend.png\", variable_legend1 + \"_plot.png\")\n",
    "print(filepath4_new)\n",
    "\n",
    "#Plot\n",
    "markerSize = 6\n",
    "fontSize = 18\n",
    "\n",
    "fig = plt.figure(dpi= 200, figsize=(8,6)) #1200 , figsize=(10, 10)\n",
    "\n",
    "for x in range(0, n_classes):\n",
    "\n",
    "    \n",
    "    idx = (classif == x)\n",
    "    name = list_unique[x]\n",
    "   \n",
    "    # colours_sub = list(compress(colours, idx)) #required to index list\n",
    "    colours_sub = np.asarray(colourmap_updated[x]).reshape(1,-1)        \n",
    "\n",
    "    scatter = plt.scatter(embedding2[idx, 0], embedding2[idx, 1],\n",
    "                              c=colours_sub, label = name,\n",
    "                              s=15, alpha= .7, edgecolors= 'none')\n",
    "\n",
    "#Settings\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "lgnd = plt.legend(ncol=1, fontsize= fontSize, loc='center right', bbox_to_anchor=(1.4, 0.5),\n",
    "                  markerscale= 5, scatterpoints=1)\n",
    "export_legend(lgnd, filepath2= filepath3_new)\n",
    "#lgnd.remove()\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(filepath4_new, dpi=\"figure\")\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
